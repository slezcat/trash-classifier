{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECK GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEANING IMAGES\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> You can skip this part unless you add new data\n",
    "</div>\n",
    "\n",
    "Remove dodgy images also convert transparent background images\n",
    "\n",
    "**Note:** The unwanted files will be moved to unwanted directory in case you need them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imghdr\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import hashlib\n",
    "\n",
    "data_dir = os.path.join('data', 'raw_data')\n",
    "unwanted_dir = os.path.join('data', 'unwanted')\n",
    "\n",
    "image_exts = ['jpeg', 'jpg', 'bmp', 'png']\n",
    "\n",
    "# Create a dictionary to store the hashes of processed images\n",
    "processed_images = {}\n",
    "\n",
    "def calculate_image_hash(img):\n",
    "    return hashlib.md5(img.tobytes()).hexdigest()\n",
    "\n",
    "# Create the 'unwanted' directory if it doesn't exist\n",
    "os.makedirs(unwanted_dir, exist_ok=True)\n",
    "\n",
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts:\n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                # Move the unwanted file to the 'unwanted' directory\n",
    "                os.rename(image_path, os.path.join(unwanted_dir, image))\n",
    "            else:\n",
    "                # Convert palette images with transparency to RGBA using Pillow\n",
    "                pil_img = Image.open(image_path)\n",
    "                if 'P' in pil_img.mode and 'transparency' in pil_img.info:\n",
    "                    img = cv2.cvtColor(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), cv2.COLOR_RGB2RGBA)\n",
    "                    \n",
    "                    # Calculate the hash of the modified image\n",
    "                    img_hash = calculate_image_hash(img)\n",
    "                    \n",
    "                    if img_hash not in processed_images:\n",
    "                        # Save the modified image in the same directory\n",
    "                        cv2.imwrite(image_path, img)\n",
    "                        \n",
    "                        # Add the image hash to the dictionary of processed images\n",
    "                        processed_images[img_hash] = image_path\n",
    "                    else:\n",
    "                        # If the same image (based on content) exists, remove it\n",
    "                        os.remove(image_path)\n",
    "                        print('Duplicate image removed:', image_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Issue with image {}'.format(image_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECK DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "data_dir = \"data/raw_data/\"\n",
    "# Define source and destination directories\n",
    "source_dirs = os.listdir(data_dir)\n",
    "print('classes:', source_dirs)\n",
    "\n",
    "# Check if the destination directories already exist\n",
    "train_dest = os.path.join('data', 'train')\n",
    "valid_dest = os.path.join('data', 'valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> you can skip this part below also if there is already training and validation directory unless you want to delete and create a new ones\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the data from data/raw_data to training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training and validation data\n",
    "train_dir_exists = os.path.exists(train_dest)\n",
    "valid_dir_exists = os.path.exists(valid_dest)\n",
    "\n",
    "if train_dir_exists or valid_dir_exists:\n",
    "    # Ask the user for their choice\n",
    "    choice = input(\"Destination directories already exist. Do you want to:\\n\"\n",
    "                   \"1. Skip the process (S)\\n\"\n",
    "                   \"2. Delete existing directories and create new ones (D)\\n\"\n",
    "                   \"Enter 'S' or 'D': \").strip().lower()\n",
    "\n",
    "    if choice != 's' and choice != 'd':\n",
    "        print(\"Invalid choice. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    if choice == 's':\n",
    "        print(\"Skipping the process.\")\n",
    "        exit()\n",
    "    elif choice == 'd':\n",
    "        print(\"Deleting existing directories and creating new ones.\")\n",
    "\n",
    "        if train_dir_exists:\n",
    "            shutil.rmtree(train_dest)\n",
    "        if valid_dir_exists:\n",
    "            shutil.rmtree(valid_dest)\n",
    "\n",
    "# Set the training-validation split ratio\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Create destination directories\n",
    "os.makedirs(train_dest, exist_ok=True)\n",
    "os.makedirs(valid_dest, exist_ok=True)\n",
    "\n",
    "# Initialize lists to track images in training and validation sets\n",
    "training_images = []\n",
    "validation_images = []\n",
    "\n",
    "# Loop through source directories\n",
    "for source_dir in source_dirs:\n",
    "    source_dir_path = os.path.join(data_dir, source_dir)\n",
    "    train_class_dest = os.path.join(train_dest, source_dir)\n",
    "    valid_class_dest = os.path.join(valid_dest, source_dir)\n",
    "\n",
    "    os.makedirs(train_class_dest, exist_ok=True)\n",
    "    os.makedirs(valid_class_dest, exist_ok=True)\n",
    "\n",
    "    files = os.listdir(source_dir_path)\n",
    "    \n",
    "    if len(set(files)) != len(files):\n",
    "        print(f\"Warning: Duplicate filenames found in {source_dir}. Please ensure all filenames are unique.\")\n",
    "    \n",
    "    random.shuffle(files)  # Shuffle the list once\n",
    "\n",
    "    split_point = int(len(files) * split_ratio)\n",
    "\n",
    "    # Copy files to training and validation destinations and track them\n",
    "    for file in files[:split_point]:\n",
    "        image_path = os.path.join(train_class_dest, file)\n",
    "        training_images.append(image_path)\n",
    "        shutil.copy(os.path.join(source_dir_path, file), image_path)\n",
    "    for file in files[split_point:]:\n",
    "        image_path = os.path.join(valid_class_dest, file)\n",
    "        validation_images.append(image_path)\n",
    "        shutil.copy(os.path.join(source_dir_path, file), image_path)\n",
    "\n",
    "# Check for duplicates between training and validation sets\n",
    "duplicates = set(training_images) & set(validation_images)\n",
    "\n",
    "if duplicates:\n",
    "    print(f\"Warning: Duplicates found between training and validation sets: {duplicates}\")\n",
    "else:\n",
    "    print(\"No duplicates found between training and validation sets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSPECT THE IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Define the directory for inspection (e.g., train or valid)\n",
    "inspection_dir = train_dest  # You can change this to valid_dest if needed\n",
    "\n",
    "# List the class directories within the inspection directory\n",
    "class_dirs = os.listdir(inspection_dir)\n",
    "\n",
    "# Number of rows and columns for each class collage\n",
    "num_rows = len(class_dirs)  # One row per class\n",
    "num_cols = 5\n",
    "\n",
    "# Create a new figure\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Loop through each class to display a 5x5 collage\n",
    "for class_index, class_dir in enumerate(class_dirs):\n",
    "    class_path = os.path.join(inspection_dir, class_dir)\n",
    "    class_files = os.listdir(class_path)\n",
    "\n",
    "    num_images_to_inspect = min(num_cols, len(class_files))\n",
    "\n",
    "    for i in range(num_images_to_inspect):\n",
    "        img_path = os.path.join(class_path, class_files[i])\n",
    "        img = mpimg.imread(img_path)\n",
    "\n",
    "        # Add a subplot to the figure\n",
    "        ax = fig.add_subplot(num_rows, num_cols, class_index * num_cols + i + 1)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(class_dir)\n",
    "        ax.axis('off')\n",
    "\n",
    "# Adjust layout and display the collage\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "    rescale=1./255.,\n",
    "\trotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = training_datagen.flow_from_directory(\n",
    "    train_dest,\n",
    "    target_size=(224,224),\n",
    "    class_mode='categorical',\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "\tvalid_dest,\n",
    "\ttarget_size=(224,224),\n",
    "\tclass_mode='categorical',\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "mobilenet_v3 = \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/classification/5\"\n",
    "\n",
    "feature_extractor_model = mobilenet_v3\n",
    "\n",
    "feature_extractor_layer = hub.KerasLayer(\n",
    "    feature_extractor_model,\n",
    "    input_shape=(224, 224, 3),\n",
    "    trainable=False)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_extractor_layer,\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(6,activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALLBACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import datetime\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Don't run cell below if you want to save the previous logs\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "shutil.rmtree('./logs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    verbose=1,\n",
    "                    callbacks=[tensorboard_callback,early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCURACY\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Running cell below will interrupt the training model process\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract training and validation accuracy values from the 'history' object\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "print('acc :',acc)\n",
    "print('val_acc :',val_acc)\n",
    "\n",
    "# Extract training and validation loss values from the 'history' object\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "print('loss :',loss)\n",
    "print('val_loss :',val_loss)\n",
    "\n",
    "# Create a new figure with two subplots\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)  # First subplot (top)\n",
    "plt.plot(acc, label='Training Accuracy')  # Plot training accuracy\n",
    "plt.plot(val_acc, label='Validation Accuracy')  # Plot validation accuracy\n",
    "plt.legend(loc='lower right')  # Add a legend in the lower right corner\n",
    "plt.ylabel('Accuracy')  # Label for the y-axis\n",
    "plt.ylim([min(plt.ylim()), 1])  # Set y-axis limits\n",
    "plt.title('Training and Validation Accuracy')  # Title for the subplot\n",
    "\n",
    "plt.subplot(2, 1, 2)  # Second subplot (bottom)\n",
    "plt.plot(loss, label='Training Loss')  # Plot training loss\n",
    "plt.plot(val_loss, label='Validation Loss')  # Plot validation loss\n",
    "plt.legend(loc='upper right')  # Add a legend in the upper right corner\n",
    "plt.ylabel('Cross Entropy')  # Label for the y-axis\n",
    "plt.ylim([0, 1.0])  # Set y-axis limits\n",
    "plt.title('Training and Validation Loss')  # Title for the subplot\n",
    "plt.xlabel('epoch')  # Label for the x-axis\n",
    "plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_labels = [\"Cardboard\", \"Glass\", \"Metal\", \"Organic\", \"Paper\",\"Plastic\"]\n",
    "\n",
    "# Path to the directory containing your test images\n",
    "test_dir = os.path.join('data','test')\n",
    "\n",
    "# Get a list of all image files in the test directory\n",
    "image_paths = [os.path.join(test_dir, file) for file in os.listdir(test_dir) if file.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "for image_path in image_paths:\n",
    "    # Load and preprocess the image using Pillow (PIL)\n",
    "    img = load_img(image_path, target_size=(224, 224))  # Load and resize the image\n",
    "    x = img_to_array(img)  # Convert the image to a NumPy array\n",
    "    x = x / 255.0  # Normalize the pixel values to the range [0, 1]\n",
    "\n",
    "    # Predict using the model\n",
    "    yhat = model.predict(np.expand_dims(x, axis=0))\n",
    "    predicted_class = np.argmax(yhat, axis=1)[0]\n",
    "    predicted_label = class_labels[predicted_class]\n",
    "\n",
    "    print(f'Predicted class for {image_path} is {predicted_label}')\n",
    "    print(f'Class index: {predicted_class}')\n",
    "\n",
    "    plt.imshow(x)  # Display the resized image\n",
    "    plt.title(f'Predicted class: {predicted_label}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATE SAVED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "export_dir = 'saved_model/1'\n",
    "tf.saved_model.save(model, export_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
